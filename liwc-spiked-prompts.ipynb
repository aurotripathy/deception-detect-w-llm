{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiments with dataset in paper,\n",
    "Explainable Verbal Deception Detection using Transformers\n",
    "Loukas Ilias, Felix Soldner and Bennett Kleinberg\n",
    "\"\"\"\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]  # source the ~/.zshrc file\n",
    "\n",
    "# https://platform.openai.com/docs/guides/rate-limits/error-mitigation\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "# constants, until you change them ;-)\n",
    "new_line = '\\n'\n",
    "nb_test_samples = 10\n",
    "nb_few_shot_samples_of_each_class =3 # truth and deception\n",
    "delimiter = '```\\n'\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"text-davinci-003\"\n",
    "MODEL = \"gpt-4\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1640, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv ('sign_events_data_statements.csv')\n",
    "# simple EDA\n",
    "# print(df)\n",
    "# print(df.columns)\n",
    "print(f'shape: {df.shape}')  # should be 1640 x 6\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the LIWC markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1640, 101)\n",
      "Index(['signevent', 'q1', 'q2', 'unid', 'id', 'outcome_class', 'Segment', 'WC',\n",
      "       'Analytic', 'Clout',\n",
      "       ...\n",
      "       'Colon', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro',\n",
      "       'Parenth', 'OtherP', 'Emoji'],\n",
      "      dtype='object', length=101)\n",
      "['AllPunc']\n",
      "['Analytic', 'Apostro', 'Authentic', 'Clout', 'Colon', 'Comma', 'Dash', 'Dic', 'Emoji', 'Exclam']\n",
      "['OtherP', 'Parenth', 'Period', 'QMark', 'Quote', 'Segment', 'SemiC', 'Sixltr', 'Tone', 'WC']\n",
      "['WPS', 'achieve', 'adj', 'adverb', 'affect', 'affiliation', 'anger', 'anx', 'article', 'assent']\n",
      "['auxverb', 'bio', 'body', 'cause', 'certain', 'cogproc', 'compare', 'conj', 'death', 'differ']\n",
      "['discrep', 'drives', 'family', 'feel', 'female', 'filler', 'focusfuture', 'focuspast', 'focuspresent', 'friend']\n",
      "['function', 'health', 'hear', 'home', 'i', 'id', 'informal', 'ingest', 'insight', 'interrog']\n",
      "['ipron', 'leisure', 'male', 'money', 'motion', 'negate', 'negemo', 'netspeak', 'nonflu', 'number']\n",
      "['outcome_class', 'percept', 'posemo', 'power', 'ppron', 'prep', 'pronoun', 'q1', 'q2', 'quant']\n",
      "['relativ', 'relig', 'reward', 'risk', 'sad', 'see', 'sexual', 'shehe', 'signevent', 'social']\n",
      "['space', 'swear', 'tentat', 'they', 'time', 'unid', 'verb', 'we', 'work', 'you']\n",
      "      ingest   bio  Analytic  number  leisure  Apostro  focuspast  reward   \n",
      "0       0.00  0.88     27.78    1.77     1.77     0.00       4.42    3.54  \\\n",
      "1       0.00  0.00     52.71    4.44     1.11     0.00      10.00    0.00   \n",
      "2       1.94  3.88     51.60    0.00     1.94     1.94       4.85    3.88   \n",
      "3       0.00  0.00     74.02    1.49     5.97     0.00       0.00    2.99   \n",
      "4       4.40  4.40     84.75    1.10     5.49     1.10       2.20    2.20   \n",
      "...      ...   ...       ...     ...      ...      ...        ...     ...   \n",
      "1635    0.00  0.80     61.67    0.80     0.80     4.80       3.20    1.60   \n",
      "1636    0.00  0.00     10.78    2.13     2.13     0.00       0.00    0.00   \n",
      "1637    0.00  4.48     62.69    0.00     1.49     5.97       7.46    2.99   \n",
      "1638    0.00  0.00     97.53   11.11     6.67     0.00       8.89    0.00   \n",
      "1639    6.67  6.67     88.08    2.22    11.11     0.00       0.00    2.22   \n",
      "\n",
      "       WC  pronoun  \n",
      "0     113    15.04  \n",
      "1      90    18.89  \n",
      "2     103    11.65  \n",
      "3      67    11.94  \n",
      "4      91    14.29  \n",
      "...   ...      ...  \n",
      "1635  125    16.00  \n",
      "1636   47    21.28  \n",
      "1637   67    13.43  \n",
      "1638   45     4.44  \n",
      "1639   45     8.89  \n",
      "\n",
      "[1640 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "liwc_15 = pd.read_csv ('LIWC-15 Results - sign_events_data_statements - LIWC Analysis')\n",
    "# simple EDA\n",
    "\n",
    "print(f'shape: {liwc_15.shape}')  # should be 1640, \n",
    "print(liwc_15.columns)\n",
    "cols = sorted(liwc_15.columns)\n",
    "nb_attrib_per_line = 10\n",
    "print_buf = []\n",
    "for i, attrib in enumerate(cols):\n",
    "    print_buf.append(attrib)\n",
    "    if i % nb_attrib_per_line == 0:\n",
    "        print(print_buf)\n",
    "        print_buf = []\n",
    "\n",
    "truth_markers = liwc_15[['q1', 'q2', 'ingest', 'bio', 'Analytic', 'number', 'leisure', 'focusfuture']]\n",
    "deception_markers = liwc_15[['q1', 'q2', 'Apostro', 'focuspast', 'reward', 'WC', 'pronoun', 'ppron', 'Exclam', 'Tone']]\n",
    "liwc_markers = liwc_15[['ingest', 'bio', 'Analytic', 'number', 'leisure', 'Apostro', 'focuspast', 'reward', 'WC', 'pronoun']]\n",
    "# print(truth_markers)\n",
    "# print(deception_markers)\n",
    "print(liwc_markers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some quick test to see how the truth/deceit markers are bahaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: deceptive\n",
      "ingest        6.67\n",
      "bio           6.67\n",
      "Analytic     88.08\n",
      "number        2.22\n",
      "leisure      11.11\n",
      "Apostro       0.00\n",
      "focuspast     0.00\n",
      "reward        2.22\n",
      "WC           45.00\n",
      "pronoun       8.89\n",
      "Name: 1639, dtype: float64\n",
      "q1:\n",
      " Going to meet up with friends. Have lunch and drinks. Then we will get the train and go to a rave\n",
      "which lasts from 7pm-3am\n",
      "q2:\n",
      " We have booked train tickets. Ordered rave tickets. Have a group chat about it and arrangements to\n",
      "meet for lunch.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "row = 1639\n",
    "print('class:', 'truthful' if df.iloc[row]['outcome_class'] == 't' else 'deceptive')\n",
    "print(liwc_markers.iloc[row])\n",
    "print(f'q1:\\n {textwrap.fill(df.iloc[row][\"q1\"], 100)}')\n",
    "print(f'q2:\\n {textwrap.fill(df.iloc[row][\"q2\"], 100)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth df shape: (783, 6)\n",
      "                                             signevent   \n",
      "0                                  My brothers wedding  \\\n",
      "1                   Going to collect 2 new pet rabbits   \n",
      "2    Getting dinner with my friend Shan and my boyf...   \n",
      "3    mountain bike ride with my boyfriend and daughter   \n",
      "4    I will be going to the cat cafe in Glasgow on ...   \n",
      "..                                                 ...   \n",
      "778                          Go to NJ to visit cousins   \n",
      "779  I am going to visit my mum and gran who I've n...   \n",
      "780                                           Swimming   \n",
      "781                    Going for coffee with the girls   \n",
      "782                    Going to the cinema with Yasmin   \n",
      "\n",
      "                                                    q1   \n",
      "0    My little brother is getting married next Satu...  \\\n",
      "1    I will be driving for 80-90 minutes across Lon...   \n",
      "2    We were planning to get dinner somewhere near ...   \n",
      "3    We are going to cannock chase with the mountai...   \n",
      "4    I will be getting up Tuesday morning to go int...   \n",
      "..                                                 ...   \n",
      "778  I am going to take a train and then a bus to N...   \n",
      "779  I am going to get on a plane and fly to Buchar...   \n",
      "780  I bring my little girl swimming all the time s...   \n",
      "781  We all meet after we drop the kids ff at schoo...   \n",
      "782  I am meeting Yasmin at the train station tonig...   \n",
      "\n",
      "                                                    q2      unid   id   \n",
      "0    My brother and Kate have a daughter who will b...  FU304384    1  \\\n",
      "1    I saw the as for them a week ago but was going...  jr125663    2   \n",
      "2    I haven't seen Shan in a while and have been m...  xE150711    3   \n",
      "3    We will be taking our trek and wonder mountain...  RA263881    4   \n",
      "4    I have looked into the cat cafe to know that t...  RD298286    5   \n",
      "..                                                 ...       ...  ...   \n",
      "778  I am leaving on Saturday to their house. It wi...  OK943376  779   \n",
      "779  I will not be at work next week and I have a p...  sM811211  780   \n",
      "780  We do it weekly and i am currently looking a c...  OD017473  781   \n",
      "781  The girls are called Joanne and Julie although...  cg842481  782   \n",
      "782  The incredible 2 starts at savoy cinema at 8:3...  Lj421188  783   \n",
      "\n",
      "    outcome_class  \n",
      "0        truthful  \n",
      "1        truthful  \n",
      "2        truthful  \n",
      "3        truthful  \n",
      "4        truthful  \n",
      "..            ...  \n",
      "778      truthful  \n",
      "779      truthful  \n",
      "780      truthful  \n",
      "781      truthful  \n",
      "782      truthful  \n",
      "\n",
      "[783 rows x 6 columns]\n",
      "deceit df shape: (857, 6)\n",
      "                                              signevent   \n",
      "783   Going to the cat cafe in Glasgow on Tuesday fo...  \\\n",
      "784   We will be headed to Wales for a motorcycle ho...   \n",
      "785                           Training for a trail race   \n",
      "786   My husband and I will be heading to the Librar...   \n",
      "787   I am going to spend the whole day with my neic...   \n",
      "...                                                 ...   \n",
      "1635  Taking part in a 6 mile walk with a friend of ...   \n",
      "1636               Taking my Nephew to a Zoology museum   \n",
      "1637  Me and my best friend Cara are going to the zo...   \n",
      "1638                          The RAF 100 Bicycle Trail   \n",
      "1639        Going to a drum and bass rave with friends    \n",
      "\n",
      "                                                     q1   \n",
      "783   I'm going to the cat cafe where I met my girlf...  \\\n",
      "784   On Monday we are taking the train to Cardiff. ...   \n",
      "785   Ok so this is my first ever running race to he...   \n",
      "786   My husband and I are heading to Mauritius the ...   \n",
      "787   I am going to be spending a whole day with my ...   \n",
      "...                                                 ...   \n",
      "1635  I'm going on a walk with a friend of mine and ...   \n",
      "1636  I am going to a museum in Manchester that focu...   \n",
      "1637  We used to be housemates and always watched th...   \n",
      "1638  The RAF 100 Bicycle Trail is a commemorative t...   \n",
      "1639  Going to meet up with friends. Have lunch and ...   \n",
      "\n",
      "                                                     q2      unid    id   \n",
      "783   Well, it was the place where I met my girlfrie...  Ko917447   784  \\\n",
      "784   I'm not sure really as its not something booke...  RL904488   785   \n",
      "785   So I have been training for months for this I ...  ry285586   786   \n",
      "786   We'll be going to our local library in Chorlto...  GE115682   787   \n",
      "787   My sister really does live in scotland and I d...  if897876   788   \n",
      "...                                                 ...       ...   ...   \n",
      "1635  I love walking, and go a lot with my partner a...  jS030001  1636   \n",
      "1636  His name is Jack and he is 10. My brother (his...  Vp529563  1637   \n",
      "1637  Cara and I have been friends since high school...  Bn541159  1638   \n",
      "1638  The Trail used to be called the RAF 100 Voices...  WL145697  1639   \n",
      "1639  We have booked train tickets. Ordered rave tic...  AE402554  1640   \n",
      "\n",
      "     outcome_class  \n",
      "783      deceptive  \n",
      "784      deceptive  \n",
      "785      deceptive  \n",
      "786      deceptive  \n",
      "787      deceptive  \n",
      "...            ...  \n",
      "1635     deceptive  \n",
      "1636     deceptive  \n",
      "1637     deceptive  \n",
      "1638     deceptive  \n",
      "1639     deceptive  \n",
      "\n",
      "[857 rows x 6 columns]\n",
      "non-repeating random numbers are:\n",
      "random truth list:\n",
      ",                                  signevent   \n",
      "778              Go to NJ to visit cousins  \\\n",
      "670  Go for a birthday meal with my family   \n",
      "605        My 25th birthday next Wednesday   \n",
      "\n",
      "                                                    q1   \n",
      "778  I am going to take a train and then a bus to N...  \\\n",
      "670  It is my fiance's Grandad's birthday. There wi...   \n",
      "605  I'll be spending the morning with my little bo...   \n",
      "\n",
      "                                                    q2      unid   id   \n",
      "778  I am leaving on Saturday to their house. It wi...  OK943376  779  \\\n",
      "670  John will be 90 so it is a special occasion. H...  Kv274315  671   \n",
      "605  My date of birth is 25/07/1993 which means nex...  CE409808  606   \n",
      "\n",
      "    outcome_class  \n",
      "778      truthful  \n",
      "670      truthful  \n",
      "605      truthful  \n",
      "truth indices:\" [778, 670, 605]\n",
      "non-repeating random numbers are:\n",
      "random deceit list:\n",
      ",                                               signevent   \n",
      "1146                   Going paddleboarding wih my son.  \\\n",
      "898   I am off to the cat cafe in Glasgow on Tuesday...   \n",
      "907                         I am meeting my Nephew Kian   \n",
      "\n",
      "                                                     q1   \n",
      "1146  I'll be taking my son paddleboarding on Friday...  \\\n",
      "898   I am going to travel from Newcastle to Glasgow...   \n",
      "907   On Saturday I will be meeting my new nephew Ki...   \n",
      "\n",
      "                                                     q2      unid    id   \n",
      "1146  After watching someone on YouTube, my son had ...  Kb735881  1147  \\\n",
      "898   I am catching the 10.30 train from Newcastle t...  fn651386   899   \n",
      "907   Kian was in the special care baby unit for 3 d...  Ep843196   908   \n",
      "\n",
      "     outcome_class  \n",
      "1146     deceptive  \n",
      "898      deceptive  \n",
      "907      deceptive  \n",
      "deceit indices: [1146, 898, 907]\n",
      "truth + deceit indices\" [778, 670, 605, 1146, 898, 907]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5602/159798689.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  truth_df['outcome_class'] = df['outcome_class'].replace('t','truthful')\n",
      "/tmp/ipykernel_5602/159798689.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deceit_df['outcome_class'] = df['outcome_class'].replace('d','deceptive')\n"
     ]
    }
   ],
   "source": [
    "def filter_by_class(df, category):\n",
    "   return df[df['outcome_class']== category]\n",
    "\n",
    "truth_df = filter_by_class(df, 't')\n",
    "# print(truth_df)\n",
    "print(f'truth df shape: {truth_df.shape}')  # should be 1640 x 6\n",
    "\n",
    "# replace with a more expressive word, truthful\n",
    "truth_df['outcome_class'] = df['outcome_class'].replace('t','truthful')\n",
    "print(truth_df)\n",
    "\n",
    "deceit_df = filter_by_class(df, 'd')\n",
    "# print(deceit_df)\n",
    "print(f'deceit df shape: {deceit_df.shape}')  # should be 1640 x 6\n",
    "\n",
    "# replace with a more expressive word, deceitful\n",
    "deceit_df['outcome_class'] = df['outcome_class'].replace('d','deceptive')\n",
    "print(deceit_df)\n",
    "\n",
    "# pick random non-repeating rows\n",
    "def pick_randon_non_repeating(df, quantity):\n",
    "    import random\n",
    "    rand_df = pd.DataFrame()\n",
    "    random_list = random.sample(range(df.shape[0]), quantity)\n",
    "    print(\"non-repeating random numbers are:\")\n",
    "    return df.iloc[random_list], random_list\n",
    "\n",
    "random_truth_df, truth_indices_list = pick_randon_non_repeating(truth_df, nb_few_shot_samples_of_each_class)\n",
    "print(f'random truth list:\\n, {random_truth_df}')\n",
    "print(f'truth indices:\" {truth_indices_list}')\n",
    "\n",
    "random_deceit_df, deceit_indices_list = pick_randon_non_repeating(deceit_df, nb_few_shot_samples_of_each_class)\n",
    "print(f'random deceit list:\\n, {random_deceit_df}')\n",
    "deceit_indices_list = [x + truth_df.shape[0] for x in deceit_indices_list] # do this to exclude from poriginal list\n",
    "print(f'deceit indices: {deceit_indices_list}')\n",
    "\n",
    "random_truth_deceit_df = pd.concat([random_truth_df, random_deceit_df])\n",
    "few_shot_list = truth_indices_list + deceit_indices_list\n",
    "print(f'truth + deceit indices\" {few_shot_list}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the OpenAI call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_chat_completion_with_backoff(prompt, model=\"gpt-3.5-turbe\"):\n",
    "    return get_chat_completion(prompt, model)\n",
    "\n",
    "def get_completion(prompt, model='text-davinci-003'):\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        model=model\n",
    "    )\n",
    "    return response.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = f\"\"\"\n",
    "You are tasked to classify the response to questions into two classes: truthful or deceptive.\n",
    "You'll be presented with three pieces of information on activities:\n",
    "(1) The title of the activity.\n",
    "(2) Response to question #1: “Please describe your activity. Be as specific as possible.”\n",
    "(3) Response to question #2: “What information can you give us to reassure us that you are telling the truth”\n",
    "Complete the response with either 'truthful' or 'deceptive'.\n",
    "\n",
    "Here are a few examples delimited by triple backticks:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_1_heading = \"\"\"Response #1:\\n\"\"\"\n",
    "response_2_heading = \"\"\"Response #2:\\n\"\"\"\n",
    "\n",
    "def construct_activity_scenario(row):\n",
    "    # activity_header = 'Title of the Activity: ' + new_line\n",
    "    activity_header = 'Activity: ' + new_line\n",
    "    activity_description_header = 'Question #1: \\nPlease describe your activity. Be as specific as possible.'\n",
    "\n",
    "    activity_reassurance_header = 'Question #2: \\nWhat information can you give us to reassure us that you are telling the truth?'\n",
    "\n",
    "    activity = activity_header + row['signevent'] + new_line\n",
    "    q1 = activity_description_header + new_line + response_1_heading + row['q1'] + new_line\n",
    "    q2 = activity_reassurance_header + new_line + response_2_heading + row['q2'] + new_line\n",
    "    return activity + q1 + q2\n",
    "\n",
    "def construct_outcome(row):\n",
    "    outcome = \"Is the response truthful or deceptive?\\n\"\n",
    "    return outcome  + row['outcome_class'] + new_line\n",
    "\n",
    "def construct_liwc_json(row):\n",
    "    pass\n",
    "\n",
    "def construct_few_shot_prompt(few_shot_df, infer_row):\n",
    "    # constructed as a list\n",
    "    prompt = []\n",
    "    prompt.append(intro)\n",
    "    \n",
    "    for _, row in few_shot_df.iterrows():\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(construct_activity_scenario(row))\n",
    "        prompt.append(construct_outcome(row))\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(new_line)    \n",
    "\n",
    "    prompt.append(delimiter)\n",
    "    prompt.append(construct_activity_scenario(infer_row))\n",
    "    prompt.append(construct_outcome(infer_row)) # has to have a blank outcome to be filled by the llm\n",
    "    prompt.append(delimiter)\n",
    "\n",
    "\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_indices(df, total, exclude_list):\n",
    "    import random\n",
    "    rand_list = []\n",
    "    count = 0\n",
    "    while count < total:\n",
    "        rand_row = random.randrange(df.shape[0])\n",
    "        if rand_row not in exclude_list:\n",
    "            rand_list.append(rand_row)\n",
    "            count += 1\n",
    "    return rand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test indices: [1305, 970, 109, 416, 1256, 1229, 477, 338, 1400, 733]\n"
     ]
    }
   ],
   "source": [
    "test_indices = create_test_indices(df, nb_test_samples, few_shot_list)  # exclude the ones in the few shot list\n",
    "# test_indices = [1435]\n",
    "print(f'test indices: {test_indices}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5602/3980368784.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  infer_row['outcome_class'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 1305 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 970 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 109 GROUND TRUTH: truthful, RESPONSE: truthful - correct\n",
      "INDEX: 416 GROUND TRUTH: truthful, RESPONSE: truthful - correct\n",
      "INDEX: 1256 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 1229 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 477 GROUND TRUTH: truthful, RESPONSE: deceptive - wrong\n",
      "INDEX: 338 GROUND TRUTH: truthful, RESPONSE: truthful - correct\n",
      "INDEX: 1400 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 733 GROUND TRUTH: truthful, RESPONSE: truthful - correct\n"
     ]
    }
   ],
   "source": [
    "y_ground_truth = []  # for computing F1-score\n",
    "y_predicted = []\n",
    "\n",
    "for index in test_indices:\n",
    "    infer_row = df.loc[index]  \n",
    "    # print(f'Inferring the `class_outcome` for:\\n{infer_row}')\n",
    "    ground_truth = 'truthful' if infer_row['outcome_class'] == 't' else 'deceptive'\n",
    "    # mask the `outcome_class` field since you want to predict it\n",
    "    infer_row['outcome_class'] = ''\n",
    "\n",
    "    # print(f'Original\\n:{df.loc[index]}')\n",
    "    # print(f'infer row\\n: {infer_row}')\n",
    "\n",
    "    prompt = construct_few_shot_prompt(random_truth_deceit_df, infer_row)\n",
    "    prompt = ''.join(prompt)\n",
    "    \n",
    "    # print(f'{prompt}')\n",
    "\n",
    "    response = get_chat_completion_with_backoff(\n",
    "        prompt=prompt,\n",
    "        model=MODEL,\n",
    "    )    \n",
    "        \n",
    "    print(f'INDEX: {index} GROUND TRUTH: {ground_truth}, RESPONSE: {response} - {\"wrong\" if ground_truth != response else \"correct\"}')\n",
    "    y_ground_truth.append(ground_truth)\n",
    "    y_predicted.append(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1-score: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('Weighted F1-score:', f1_score(y_ground_truth, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyagi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
