{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiments with dataset in paper,\n",
    "Explainable Verbal Deception Detection using Transformers\n",
    "Loukas Ilias, Felix Soldner and Bennett Kleinberg\n",
    "uses LIWC-15\n",
    "\"\"\"\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]  # source the ~/.zshrc file\n",
    "\n",
    "# https://platform.openai.com/docs/guides/rate-limits/error-mitigation\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "# constants, until you change them ;-)\n",
    "new_line = '\\n'\n",
    "nb_test_samples = 20\n",
    "nb_few_shot_samples_of_each_class =3 # truth and deception\n",
    "delimiter = '```\\n'\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"text-davinci-003\"\n",
    "MODEL = \"gpt-4\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1640, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                               signevent   \n",
       "0                                   My brothers wedding  \\\n",
       "1                    Going to collect 2 new pet rabbits   \n",
       "2     Getting dinner with my friend Shan and my boyf...   \n",
       "3     mountain bike ride with my boyfriend and daughter   \n",
       "4     I will be going to the cat cafe in Glasgow on ...   \n",
       "...                                                 ...   \n",
       "1635  Taking part in a 6 mile walk with a friend of ...   \n",
       "1636               Taking my Nephew to a Zoology museum   \n",
       "1637  Me and my best friend Cara are going to the zo...   \n",
       "1638                          The RAF 100 Bicycle Trail   \n",
       "1639         Going to a drum and bass rave with friends   \n",
       "\n",
       "                                                     q1   \n",
       "0     My little brother is getting married next Satu...  \\\n",
       "1     I will be driving for 80-90 minutes across Lon...   \n",
       "2     We were planning to get dinner somewhere near ...   \n",
       "3     We are going to cannock chase with the mountai...   \n",
       "4     I will be getting up Tuesday morning to go int...   \n",
       "...                                                 ...   \n",
       "1635  I'm going on a walk with a friend of mine and ...   \n",
       "1636  I am going to a museum in Manchester that focu...   \n",
       "1637  We used to be housemates and always watched th...   \n",
       "1638  The RAF 100 Bicycle Trail is a commemorative t...   \n",
       "1639  Going to meet up with friends. Have lunch and ...   \n",
       "\n",
       "                                                     q2      unid    id   \n",
       "0     My brother and Kate have a daughter who will b...  FU304384     1  \\\n",
       "1     I saw the as for them a week ago but was going...  jr125663     2   \n",
       "2     I haven't seen Shan in a while and have been m...  xE150711     3   \n",
       "3     We will be taking our trek and wonder mountain...  RA263881     4   \n",
       "4     I have looked into the cat cafe to know that t...  RD298286     5   \n",
       "...                                                 ...       ...   ...   \n",
       "1635  I love walking, and go a lot with my partner a...  jS030001  1636   \n",
       "1636  His name is Jack and he is 10. My brother (his...  Vp529563  1637   \n",
       "1637  Cara and I have been friends since high school...  Bn541159  1638   \n",
       "1638  The Trail used to be called the RAF 100 Voices...  WL145697  1639   \n",
       "1639  We have booked train tickets. Ordered rave tic...  AE402554  1640   \n",
       "\n",
       "     outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
       "0                t        1  113     27.78  99.00  ...    0.0   0.00    0.0  \\\n",
       "1                t        1   90     52.71  71.09  ...    0.0   0.00    0.0   \n",
       "2                t        1  103     51.60  38.53  ...    0.0   0.97    0.0   \n",
       "3                t        1   67     74.02  93.21  ...    0.0   0.00    0.0   \n",
       "4                t        1   91     84.75  58.68  ...    0.0   0.00    0.0   \n",
       "...            ...      ...  ...       ...    ...  ...    ...    ...    ...   \n",
       "1635             d        1  125     61.67  71.23  ...    0.0   0.00    0.0   \n",
       "1636             d        1   47     10.78  66.48  ...    0.0   0.00    0.0   \n",
       "1637             d        1   67     62.69  96.31  ...    0.0   0.00    0.0   \n",
       "1638             d        1   45     97.53  74.76  ...    0.0   0.00    0.0   \n",
       "1639             d        1   45     88.08  97.69  ...    0.0   0.00    0.0   \n",
       "\n",
       "      Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
       "0        0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
       "1        0.0  1.11    0.0     0.00     0.00    0.00    0.0  \n",
       "2        0.0  0.00    0.0     1.94     0.00    0.97    0.0  \n",
       "3        0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
       "4        0.0  0.00    0.0     1.10     0.00    0.00    0.0  \n",
       "...      ...   ...    ...      ...      ...     ...    ...  \n",
       "1635     0.8  0.00    0.0     4.80     0.00    0.00    0.0  \n",
       "1636     0.0  0.00    0.0     0.00     4.26    0.00    0.0  \n",
       "1637     0.0  0.00    0.0     5.97     0.00    0.00    0.0  \n",
       "1638     0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
       "1639     0.0  2.22    0.0     0.00     0.00    0.00    0.0  \n",
       "\n",
       "[1640 rows x 101 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv ('LIWC-15 Results - sign_events_data_statements - LIWC Analysis')\n",
    "# simple EDA\n",
    "# print(df)\n",
    "# print(df.columns)\n",
    "print(f'shape: {df.shape}')  # should be 1640 x 6\n",
    "df.head\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the LIWC markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1640, 101)\n",
      "Index(['signevent', 'q1', 'q2', 'unid', 'id', 'outcome_class', 'Segment', 'WC',\n",
      "       'Analytic', 'Clout',\n",
      "       ...\n",
      "       'Colon', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro',\n",
      "       'Parenth', 'OtherP', 'Emoji'],\n",
      "      dtype='object', length=101)\n",
      "['AllPunc']\n",
      "['Analytic', 'Apostro', 'Authentic', 'Clout', 'Colon', 'Comma', 'Dash', 'Dic', 'Emoji', 'Exclam']\n",
      "['OtherP', 'Parenth', 'Period', 'QMark', 'Quote', 'Segment', 'SemiC', 'Sixltr', 'Tone', 'WC']\n",
      "['WPS', 'achieve', 'adj', 'adverb', 'affect', 'affiliation', 'anger', 'anx', 'article', 'assent']\n",
      "['auxverb', 'bio', 'body', 'cause', 'certain', 'cogproc', 'compare', 'conj', 'death', 'differ']\n",
      "['discrep', 'drives', 'family', 'feel', 'female', 'filler', 'focusfuture', 'focuspast', 'focuspresent', 'friend']\n",
      "['function', 'health', 'hear', 'home', 'i', 'id', 'informal', 'ingest', 'insight', 'interrog']\n",
      "['ipron', 'leisure', 'male', 'money', 'motion', 'negate', 'negemo', 'netspeak', 'nonflu', 'number']\n",
      "['outcome_class', 'percept', 'posemo', 'power', 'ppron', 'prep', 'pronoun', 'q1', 'q2', 'quant']\n",
      "['relativ', 'relig', 'reward', 'risk', 'sad', 'see', 'sexual', 'shehe', 'signevent', 'social']\n",
      "['space', 'swear', 'tentat', 'they', 'time', 'unid', 'verb', 'we', 'work', 'you']\n",
      "      ingest   bio  Analytic  number  leisure  Apostro  focuspast  reward   \n",
      "0       0.00  0.88     27.78    1.77     1.77     0.00       4.42    3.54  \\\n",
      "1       0.00  0.00     52.71    4.44     1.11     0.00      10.00    0.00   \n",
      "2       1.94  3.88     51.60    0.00     1.94     1.94       4.85    3.88   \n",
      "3       0.00  0.00     74.02    1.49     5.97     0.00       0.00    2.99   \n",
      "4       4.40  4.40     84.75    1.10     5.49     1.10       2.20    2.20   \n",
      "...      ...   ...       ...     ...      ...      ...        ...     ...   \n",
      "1635    0.00  0.80     61.67    0.80     0.80     4.80       3.20    1.60   \n",
      "1636    0.00  0.00     10.78    2.13     2.13     0.00       0.00    0.00   \n",
      "1637    0.00  4.48     62.69    0.00     1.49     5.97       7.46    2.99   \n",
      "1638    0.00  0.00     97.53   11.11     6.67     0.00       8.89    0.00   \n",
      "1639    6.67  6.67     88.08    2.22    11.11     0.00       0.00    2.22   \n",
      "\n",
      "       WC  pronoun  \n",
      "0     113    15.04  \n",
      "1      90    18.89  \n",
      "2     103    11.65  \n",
      "3      67    11.94  \n",
      "4      91    14.29  \n",
      "...   ...      ...  \n",
      "1635  125    16.00  \n",
      "1636   47    21.28  \n",
      "1637   67    13.43  \n",
      "1638   45     4.44  \n",
      "1639   45     8.89  \n",
      "\n",
      "[1640 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "liwc_15 = pd.read_csv ('LIWC-15 Results - sign_events_data_statements - LIWC Analysis')\n",
    "# simple EDA\n",
    "\n",
    "print(f'shape: {liwc_15.shape}')  # should be 1640, \n",
    "print(liwc_15.columns)\n",
    "cols = sorted(liwc_15.columns)\n",
    "nb_attrib_per_line = 10\n",
    "print_buf = []\n",
    "for i, attrib in enumerate(cols):\n",
    "    print_buf.append(attrib)\n",
    "    if i % nb_attrib_per_line == 0:\n",
    "        print(print_buf)\n",
    "        print_buf = []\n",
    "\n",
    "truth_markers = df[['ingest', 'bio', 'Analytic', 'number', 'leisure', 'focusfuture']]\n",
    "deception_markers = df[['Apostro', 'focuspast', 'reward', 'WC', 'pronoun', 'ppron', 'Exclam', 'Tone']]\n",
    "liwc_markers = df[['ingest', 'bio', 'Analytic', 'number', 'leisure', 'Apostro', 'focuspast', 'reward', 'WC', 'pronoun']]\n",
    "# print(truth_markers)\n",
    "# print(deception_markers)\n",
    "print(liwc_markers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some quick test to see how the truth/deceit markers are bahaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signevent                                  My brothers wedding\n",
      "q1           My little brother is getting married next Satu...\n",
      "q2           My brother and Kate have a daughter who will b...\n",
      "unid                                                  FU304384\n",
      "id                                                           1\n",
      "                                   ...                        \n",
      "Quote                                                      0.0\n",
      "Apostro                                                    0.0\n",
      "Parenth                                                    0.0\n",
      "OtherP                                                     0.0\n",
      "Emoji                                                      0.0\n",
      "Name: 0, Length: 101, dtype: object\n",
      "{\"ingest\": \"0.0\", \"bio\": \"0.88\", \"Analytic\": \"27.78\", \"number\": \"1.77\", \"leisure\": \"1.77\", \"Apostro\": \"0.0\", \"focuspast\": \"4.42\", \"reward\": \"3.54\", \"WC\": \"113\", \"pronoun\": \"15.04\"}\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import json\n",
    "# TODO see if this can be more friendlier if GPT does not know about LIWC\n",
    "def construct_liwc_attributes_json(row):\n",
    "    # print('class:', 'truthful' if df.iloc[row]['outcome_class'] == 't' else 'deceptive')\n",
    "    # print(liwc_markers.iloc[row])\n",
    "    # print(f'q1:\\n {textwrap.fill(df.iloc[row][\"q1\"], 100)}')\n",
    "    # print(f'q2:\\n {textwrap.fill(df.iloc[row][\"q2\"], 100)}')\n",
    "    \n",
    "    attributes = ['ingest', 'bio', 'Analytic', 'number', 'leisure', 'Apostro', 'focuspast', 'reward', 'WC', 'pronoun']\n",
    "    data = {}\n",
    "    for attribute in attributes:\n",
    "        data[attribute] = str(row[attribute])\n",
    "    \n",
    "    return json.dumps(data)\n",
    "\n",
    "print(df.iloc[0])\n",
    "print(construct_liwc_attributes_json(df.iloc[0].copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth df shape: (783, 101)\n",
      "                                             signevent   \n",
      "0                                  My brothers wedding  \\\n",
      "1                   Going to collect 2 new pet rabbits   \n",
      "2    Getting dinner with my friend Shan and my boyf...   \n",
      "3    mountain bike ride with my boyfriend and daughter   \n",
      "4    I will be going to the cat cafe in Glasgow on ...   \n",
      "..                                                 ...   \n",
      "778                          Go to NJ to visit cousins   \n",
      "779  I am going to visit my mum and gran who I've n...   \n",
      "780                                           Swimming   \n",
      "781                    Going for coffee with the girls   \n",
      "782                    Going to the cinema with Yasmin   \n",
      "\n",
      "                                                    q1   \n",
      "0    My little brother is getting married next Satu...  \\\n",
      "1    I will be driving for 80-90 minutes across Lon...   \n",
      "2    We were planning to get dinner somewhere near ...   \n",
      "3    We are going to cannock chase with the mountai...   \n",
      "4    I will be getting up Tuesday morning to go int...   \n",
      "..                                                 ...   \n",
      "778  I am going to take a train and then a bus to N...   \n",
      "779  I am going to get on a plane and fly to Buchar...   \n",
      "780  I bring my little girl swimming all the time s...   \n",
      "781  We all meet after we drop the kids ff at schoo...   \n",
      "782  I am meeting Yasmin at the train station tonig...   \n",
      "\n",
      "                                                    q2      unid   id   \n",
      "0    My brother and Kate have a daughter who will b...  FU304384    1  \\\n",
      "1    I saw the as for them a week ago but was going...  jr125663    2   \n",
      "2    I haven't seen Shan in a while and have been m...  xE150711    3   \n",
      "3    We will be taking our trek and wonder mountain...  RA263881    4   \n",
      "4    I have looked into the cat cafe to know that t...  RD298286    5   \n",
      "..                                                 ...       ...  ...   \n",
      "778  I am leaving on Saturday to their house. It wi...  OK943376  779   \n",
      "779  I will not be at work next week and I have a p...  sM811211  780   \n",
      "780  We do it weekly and i am currently looking a c...  OD017473  781   \n",
      "781  The girls are called Joanne and Julie although...  cg842481  782   \n",
      "782  The incredible 2 starts at savoy cinema at 8:3...  Lj421188  783   \n",
      "\n",
      "    outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "0        truthful        1  113     27.78  99.00  ...   0.00   0.00    0.0  \\\n",
      "1        truthful        1   90     52.71  71.09  ...   0.00   0.00    0.0   \n",
      "2        truthful        1  103     51.60  38.53  ...   0.00   0.97    0.0   \n",
      "3        truthful        1   67     74.02  93.21  ...   0.00   0.00    0.0   \n",
      "4        truthful        1   91     84.75  58.68  ...   0.00   0.00    0.0   \n",
      "..            ...      ...  ...       ...    ...  ...    ...    ...    ...   \n",
      "778      truthful        1   53     66.22  57.49  ...   0.00   0.00    0.0   \n",
      "779      truthful        1   44     80.14   8.65  ...   0.00   0.00    0.0   \n",
      "780      truthful        1   41     33.72  68.71  ...   0.00   0.00    0.0   \n",
      "781      truthful        1  225     45.13  73.31  ...   0.00   0.00    0.0   \n",
      "782      truthful        1   36     98.14  60.95  ...   5.56   0.00    0.0   \n",
      "\n",
      "     Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "0       0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "1       0.0  1.11    0.0     0.00      0.0    0.00    0.0  \n",
      "2       0.0  0.00    0.0     1.94      0.0    0.97    0.0  \n",
      "3       0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "4       0.0  0.00    0.0     1.10      0.0    0.00    0.0  \n",
      "..      ...   ...    ...      ...      ...     ...    ...  \n",
      "778     0.0  1.89    0.0     0.00      0.0    0.00    0.0  \n",
      "779     0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "780     0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "781     0.0  0.00    0.0     2.67      0.0    0.00    0.0  \n",
      "782     0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "\n",
      "[783 rows x 101 columns]\n",
      "deceit df shape: (857, 101)\n",
      "                                              signevent   \n",
      "783   Going to the cat cafe in Glasgow on Tuesday fo...  \\\n",
      "784   We will be headed to Wales for a motorcycle ho...   \n",
      "785                           Training for a trail race   \n",
      "786   My husband and I will be heading to the Librar...   \n",
      "787   I am going to spend the whole day with my neic...   \n",
      "...                                                 ...   \n",
      "1635  Taking part in a 6 mile walk with a friend of ...   \n",
      "1636               Taking my Nephew to a Zoology museum   \n",
      "1637  Me and my best friend Cara are going to the zo...   \n",
      "1638                          The RAF 100 Bicycle Trail   \n",
      "1639         Going to a drum and bass rave with friends   \n",
      "\n",
      "                                                     q1   \n",
      "783   I'm going to the cat cafe where I met my girlf...  \\\n",
      "784   On Monday we are taking the train to Cardiff. ...   \n",
      "785   Ok so this is my first ever running race to he...   \n",
      "786   My husband and I are heading to Mauritius the ...   \n",
      "787   I am going to be spending a whole day with my ...   \n",
      "...                                                 ...   \n",
      "1635  I'm going on a walk with a friend of mine and ...   \n",
      "1636  I am going to a museum in Manchester that focu...   \n",
      "1637  We used to be housemates and always watched th...   \n",
      "1638  The RAF 100 Bicycle Trail is a commemorative t...   \n",
      "1639  Going to meet up with friends. Have lunch and ...   \n",
      "\n",
      "                                                     q2      unid    id   \n",
      "783   Well, it was the place where I met my girlfrie...  Ko917447   784  \\\n",
      "784   I'm not sure really as its not something booke...  RL904488   785   \n",
      "785   So I have been training for months for this I ...  ry285586   786   \n",
      "786   We'll be going to our local library in Chorlto...  GE115682   787   \n",
      "787   My sister really does live in scotland and I d...  if897876   788   \n",
      "...                                                 ...       ...   ...   \n",
      "1635  I love walking, and go a lot with my partner a...  jS030001  1636   \n",
      "1636  His name is Jack and he is 10. My brother (his...  Vp529563  1637   \n",
      "1637  Cara and I have been friends since high school...  Bn541159  1638   \n",
      "1638  The Trail used to be called the RAF 100 Voices...  WL145697  1639   \n",
      "1639  We have booked train tickets. Ordered rave tic...  AE402554  1640   \n",
      "\n",
      "     outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "783      deceptive        1   86     50.06  85.24  ...    0.0    0.0    0.0  \\\n",
      "784      deceptive        1  109     64.90  82.06  ...    0.0    0.0    0.0   \n",
      "785      deceptive        1  190     23.53  15.86  ...    0.0    0.0    0.0   \n",
      "786      deceptive        1   83     73.76  97.97  ...    0.0    0.0    0.0   \n",
      "787      deceptive        1  121     53.19  28.15  ...    0.0    0.0    0.0   \n",
      "...            ...      ...  ...       ...    ...  ...    ...    ...    ...   \n",
      "1635     deceptive        1  125     61.67  71.23  ...    0.0    0.0    0.0   \n",
      "1636     deceptive        1   47     10.78  66.48  ...    0.0    0.0    0.0   \n",
      "1637     deceptive        1   67     62.69  96.31  ...    0.0    0.0    0.0   \n",
      "1638     deceptive        1   45     97.53  74.76  ...    0.0    0.0    0.0   \n",
      "1639     deceptive        1   45     88.08  97.69  ...    0.0    0.0    0.0   \n",
      "\n",
      "      Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "783     0.00  0.00    0.0     3.49     0.00     0.0    0.0  \n",
      "784     0.00  0.00    0.0     3.67     1.83     0.0    0.0  \n",
      "785     0.00  0.00    0.0     2.63     0.00     0.0    0.0  \n",
      "786     1.20  0.00    0.0     1.20     0.00     0.0    0.0  \n",
      "787     0.83  0.00    0.0     4.13     0.00     0.0    0.0  \n",
      "...      ...   ...    ...      ...      ...     ...    ...  \n",
      "1635    0.80  0.00    0.0     4.80     0.00     0.0    0.0  \n",
      "1636    0.00  0.00    0.0     0.00     4.26     0.0    0.0  \n",
      "1637    0.00  0.00    0.0     5.97     0.00     0.0    0.0  \n",
      "1638    0.00  0.00    0.0     0.00     0.00     0.0    0.0  \n",
      "1639    0.00  2.22    0.0     0.00     0.00     0.0    0.0  \n",
      "\n",
      "[857 rows x 101 columns]\n",
      "non-repeating random numbers are:\n",
      "random truth list:\n",
      ",                                              signevent   \n",
      "713                                         Church BBQ  \\\n",
      "687  Going to see Annie at her spoken-word poetry e...   \n",
      "581                              Quiz night with Derek   \n",
      "\n",
      "                                                    q1   \n",
      "713  After the sunday church meeting there will be ...  \\\n",
      "687  I am going to see Annie perform at the spoken-...   \n",
      "581  Fulwood arms start at 9pm. (if we are lucky) n...   \n",
      "\n",
      "                                                    q2      unid   id   \n",
      "713  There will be chairs, tables and blankets avai...  hY475893  714  \\\n",
      "687  I can tell you about Annie some more and the e...  Ml888645  688   \n",
      "581  That's what happens  there is a pub called the...  dg423047  582   \n",
      "\n",
      "    outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "713      truthful        1   57     89.34  70.08  ...   0.00   1.75    0.0  \\\n",
      "687      truthful        1  210     43.23  81.72  ...   0.48   0.00    0.0   \n",
      "581      truthful        1   88     80.14  54.52  ...   0.00   0.00    0.0   \n",
      "\n",
      "     Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "713     0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
      "687     0.0  2.86    0.0     0.95     0.95    0.00    0.0  \n",
      "581     0.0  0.00    0.0     1.14     2.27    1.14    0.0  \n",
      "\n",
      "[3 rows x 101 columns]\n",
      "truth indices:\" [713, 687, 581]\n",
      "non-repeating random numbers are:\n",
      "random deceit list:\n",
      ",                                               signevent   \n",
      "1190  I plan to go camping with some friends prior t...  \\\n",
      "1177  Going to take part in a 5K race for a local ch...   \n",
      "1063  I'm going to be running in a 5k.  I'm very exc...   \n",
      "\n",
      "                                                     q1   \n",
      "1190  I live in a city, but within 2 hours from here...  \\\n",
      "1177  The race is on Saturday, starting at 10am for ...   \n",
      "1063  As a part of the local holiday coming up, I'm ...   \n",
      "\n",
      "                                                     q2      unid    id   \n",
      "1190  The name of the park is Gardner State park, a ...  Yw615240  1191  \\\n",
      "1177  The race will be covered in the local press an...  IC150838  1178   \n",
      "1063  I've paid the $50 entrance fee already and hav...  PT229681  1064   \n",
      "\n",
      "     outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "1190     deceptive        1   69     90.13  55.76  ...   0.00    0.0    0.0  \\\n",
      "1177     deceptive        1   46     99.00  58.59  ...   0.00    0.0    0.0   \n",
      "1063     deceptive        1  127     90.77  31.84  ...   0.79    0.0    0.0   \n",
      "\n",
      "      Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "1190     0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
      "1177     0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
      "1063     0.0  0.79    0.0     1.57     1.57    0.79    0.0  \n",
      "\n",
      "[3 rows x 101 columns]\n",
      "deceit indices: [1190, 1177, 1063]\n",
      "truth + deceit indices\" [713, 687, 581, 1190, 1177, 1063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21503/4237064160.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  truth_df['outcome_class'] = df['outcome_class'].replace('t','truthful')\n",
      "/tmp/ipykernel_21503/4237064160.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deceit_df['outcome_class'] = df['outcome_class'].replace('d','deceptive')\n"
     ]
    }
   ],
   "source": [
    "def filter_by_class(df, category):\n",
    "   return df[df['outcome_class']== category]\n",
    "\n",
    "truth_df = filter_by_class(df, 't')\n",
    "# print(truth_df)\n",
    "print(f'truth df shape: {truth_df.shape}')  # should be 1640 x 6\n",
    "\n",
    "# replace with a more expressive word, truthful\n",
    "truth_df['outcome_class'] = df['outcome_class'].replace('t','truthful')\n",
    "print(truth_df)\n",
    "\n",
    "deceit_df = filter_by_class(df, 'd')\n",
    "# print(deceit_df)\n",
    "print(f'deceit df shape: {deceit_df.shape}')  # should be 1640 x 6\n",
    "\n",
    "# replace with a more expressive word, deceitful\n",
    "deceit_df['outcome_class'] = df['outcome_class'].replace('d','deceptive')\n",
    "print(deceit_df)\n",
    "\n",
    "# pick random non-repeating rows\n",
    "def pick_randon_non_repeating(df, quantity):\n",
    "    import random\n",
    "    rand_df = pd.DataFrame()\n",
    "    random_list = random.sample(range(df.shape[0]), quantity)\n",
    "    print(\"non-repeating random numbers are:\")\n",
    "    return df.iloc[random_list], random_list\n",
    "\n",
    "random_truth_df, truth_indices_list = pick_randon_non_repeating(truth_df, nb_few_shot_samples_of_each_class)\n",
    "print(f'random truth list:\\n, {random_truth_df}')\n",
    "print(f'truth indices:\" {truth_indices_list}')\n",
    "\n",
    "random_deceit_df, deceit_indices_list = pick_randon_non_repeating(deceit_df, nb_few_shot_samples_of_each_class)\n",
    "print(f'random deceit list:\\n, {random_deceit_df}')\n",
    "deceit_indices_list = [x + truth_df.shape[0] for x in deceit_indices_list] # do this to exclude from poriginal list\n",
    "print(f'deceit indices: {deceit_indices_list}')\n",
    "\n",
    "random_truth_deceit_df = pd.concat([random_truth_df, random_deceit_df])\n",
    "few_shot_list = truth_indices_list + deceit_indices_list\n",
    "print(f'truth + deceit indices\" {few_shot_list}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the OpenAI call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_chat_completion_with_backoff(prompt, model=\"gpt-3.5-turbe\"):\n",
    "    return get_chat_completion(prompt, model)\n",
    "\n",
    "def get_completion(prompt, model='text-davinci-003'):\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        model=model\n",
    "    )\n",
    "    return response.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = f\"\"\"\n",
    "You are tasked to classify the response to questions into two classes: truthful or deceptive.\n",
    "You'll be presented with the following pieces of information on an activity:\n",
    "(1) The title of the activity.\n",
    "(2) An answwer to a question: Please describe your activity. Be as specific as possible.\n",
    "(3) A answer to a follow-on question: What information can you give us to reassure us that you are telling the truth?\n",
    "(4) A Linguistic Inquiry Word Count (LIWC) category values as JSON data\n",
    "Using all four pieces of information, complete the response with either 'truthful' or 'deceptive'.\n",
    "\n",
    "Here are a few examples delimited by triple backticks:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_1_heading = \"\"\"Response #1:\\n\"\"\"\n",
    "response_2_heading = \"\"\"Response #2:\\n\"\"\"\n",
    "\n",
    "liwc_header = \"\"\"Linguistic Inquiry Word Count (LIWC):\\n\"\"\"\n",
    "\n",
    "def construct_activity_scenario(row):\n",
    "    # activity_header = 'Title of the Activity: ' + new_line\n",
    "    activity_header = 'Activity: ' + new_line\n",
    "    activity_description_header = 'Question #1: \\nPlease describe your activity. Be as specific as possible.'\n",
    "\n",
    "    activity_reassurance_header = 'Question #2: \\nWhat information can you give us to reassure us that you are telling the truth?'\n",
    "\n",
    "    activity = activity_header + row['signevent'] + new_line\n",
    "    q1 = activity_description_header + new_line + response_1_heading + row['q1'] + new_line\n",
    "    q2 = activity_reassurance_header + new_line + response_2_heading + row['q2'] + new_line\n",
    "    return activity + q1 + q2\n",
    "\n",
    "def construct_outcome(row):\n",
    "    outcome = \"Is the response truthful or deceptive?\\n\"\n",
    "    return outcome  + row['outcome_class'] + new_line\n",
    "\n",
    "def construct_liwc_json(row):\n",
    "    pass\n",
    "\n",
    "def construct_few_shot_prompt(few_shot_df, infer_row):\n",
    "    # constructed as a list\n",
    "    prompt = []\n",
    "    prompt.append(intro)\n",
    "    \n",
    "    for _, row in few_shot_df.iterrows():\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(construct_activity_scenario(row))\n",
    "        prompt.append(liwc_header)\n",
    "        prompt.append(construct_liwc_attributes_json(row))\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(construct_outcome(row))\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(new_line)    \n",
    "        prompt.append(new_line)\n",
    "\n",
    "    prompt.append(delimiter)\n",
    "    prompt.append(construct_activity_scenario(infer_row))\n",
    "    prompt.append(liwc_header)\n",
    "    prompt.append(construct_liwc_attributes_json(row))\n",
    "    prompt.append(delimiter) \n",
    "    prompt.append(construct_outcome(infer_row)) # has to have a blank outcome to be filled by the llm\n",
    "    prompt.append(delimiter)\n",
    "\n",
    "\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_indices(df, total, exclude_list):\n",
    "    import random\n",
    "    rand_list = []\n",
    "    count = 0\n",
    "    while count < total:\n",
    "        rand_row = random.randrange(df.shape[0])\n",
    "        if rand_row not in exclude_list:\n",
    "            rand_list.append(rand_row)\n",
    "            count += 1\n",
    "    return rand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test indices: [1175, 1477, 993, 1068, 102, 701, 1525, 1433, 1524, 914]\n"
     ]
    }
   ],
   "source": [
    "test_indices = create_test_indices(df, nb_test_samples, few_shot_list)  # exclude the ones in the few shot list\n",
    "# test_indices = [1435]\n",
    "print(f'test indices: {test_indices}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 1175 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 1477 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 993 GROUND TRUTH: deceptive, RESPONSE: deceptive - correct\n",
      "INDEX: 1068 GROUND TRUTH: deceptive, RESPONSE: deceptive - correct\n",
      "INDEX: 102 GROUND TRUTH: truthful, RESPONSE: truthful - correct\n",
      "INDEX: 701 GROUND TRUTH: truthful, RESPONSE: deceptive - wrong\n",
      "INDEX: 1525 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 1433 GROUND TRUTH: deceptive, RESPONSE: deceptive - correct\n",
      "INDEX: 1524 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n",
      "INDEX: 914 GROUND TRUTH: deceptive, RESPONSE: truthful - wrong\n"
     ]
    }
   ],
   "source": [
    "y_ground_truth = []  # for computing F1-score\n",
    "y_predicted = []\n",
    "\n",
    "for index in test_indices:\n",
    "    infer_row = df.loc[index].copy()\n",
    "    # print(f'Inferring the `class_outcome` for:\\n{infer_row}')\n",
    "    ground_truth = 'truthful' if infer_row['outcome_class'] == 't' else 'deceptive'\n",
    "    # mask the `outcome_class` field since you want to predict it\n",
    "    infer_row['outcome_class'] = ''\n",
    "\n",
    "    # print(f'Original\\n:{df.loc[index]}')\n",
    "    # print(f'infer row\\n: {infer_row}')\n",
    "\n",
    "    prompt = construct_few_shot_prompt(random_truth_deceit_df, infer_row)\n",
    "    prompt = ''.join(prompt)\n",
    "    \n",
    "    # print(f'Prompt:\\n{prompt}')\n",
    "\n",
    "    response = get_chat_completion_with_backoff(\n",
    "        prompt=prompt,\n",
    "        model=MODEL,\n",
    "    )    \n",
    "        \n",
    "    print(f'INDEX: {index} GROUND TRUTH: {ground_truth}, RESPONSE: {response} - {\"wrong\" if ground_truth != response else \"correct\"}')\n",
    "    y_ground_truth.append(ground_truth)\n",
    "    y_predicted.append(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1-score: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('Weighted F1-score:', f1_score(y_ground_truth, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyagi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
