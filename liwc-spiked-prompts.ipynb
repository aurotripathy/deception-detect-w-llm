{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiments with dataset in paper,\n",
    "Explainable Verbal Deception Detection using Transformers\n",
    "Loukas Ilias, Felix Soldner and Bennett Kleinberg\n",
    "uses LIWC-15\n",
    "\"\"\"\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]  # source the ~/.zshrc file\n",
    "\n",
    "# https://platform.openai.com/docs/guides/rate-limits/error-mitigation\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "# constants, until you change them ;-)\n",
    "new_line = '\\n'\n",
    "nb_test_samples = 10\n",
    "nb_few_shot_samples_of_each_class =3 # truth and deception\n",
    "delimiter = '```\\n'\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"text-davinci-003\"\n",
    "MODEL = \"gpt-4\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1640, 101)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                               signevent   \n",
       "0                                   My brothers wedding  \\\n",
       "1                    Going to collect 2 new pet rabbits   \n",
       "2     Getting dinner with my friend Shan and my boyf...   \n",
       "3     mountain bike ride with my boyfriend and daughter   \n",
       "4     I will be going to the cat cafe in Glasgow on ...   \n",
       "...                                                 ...   \n",
       "1635  Taking part in a 6 mile walk with a friend of ...   \n",
       "1636               Taking my Nephew to a Zoology museum   \n",
       "1637  Me and my best friend Cara are going to the zo...   \n",
       "1638                          The RAF 100 Bicycle Trail   \n",
       "1639         Going to a drum and bass rave with friends   \n",
       "\n",
       "                                                     q1   \n",
       "0     My little brother is getting married next Satu...  \\\n",
       "1     I will be driving for 80-90 minutes across Lon...   \n",
       "2     We were planning to get dinner somewhere near ...   \n",
       "3     We are going to cannock chase with the mountai...   \n",
       "4     I will be getting up Tuesday morning to go int...   \n",
       "...                                                 ...   \n",
       "1635  I'm going on a walk with a friend of mine and ...   \n",
       "1636  I am going to a museum in Manchester that focu...   \n",
       "1637  We used to be housemates and always watched th...   \n",
       "1638  The RAF 100 Bicycle Trail is a commemorative t...   \n",
       "1639  Going to meet up with friends. Have lunch and ...   \n",
       "\n",
       "                                                     q2      unid    id   \n",
       "0     My brother and Kate have a daughter who will b...  FU304384     1  \\\n",
       "1     I saw the as for them a week ago but was going...  jr125663     2   \n",
       "2     I haven't seen Shan in a while and have been m...  xE150711     3   \n",
       "3     We will be taking our trek and wonder mountain...  RA263881     4   \n",
       "4     I have looked into the cat cafe to know that t...  RD298286     5   \n",
       "...                                                 ...       ...   ...   \n",
       "1635  I love walking, and go a lot with my partner a...  jS030001  1636   \n",
       "1636  His name is Jack and he is 10. My brother (his...  Vp529563  1637   \n",
       "1637  Cara and I have been friends since high school...  Bn541159  1638   \n",
       "1638  The Trail used to be called the RAF 100 Voices...  WL145697  1639   \n",
       "1639  We have booked train tickets. Ordered rave tic...  AE402554  1640   \n",
       "\n",
       "     outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
       "0                t        1  113     27.78  99.00  ...    0.0   0.00    0.0  \\\n",
       "1                t        1   90     52.71  71.09  ...    0.0   0.00    0.0   \n",
       "2                t        1  103     51.60  38.53  ...    0.0   0.97    0.0   \n",
       "3                t        1   67     74.02  93.21  ...    0.0   0.00    0.0   \n",
       "4                t        1   91     84.75  58.68  ...    0.0   0.00    0.0   \n",
       "...            ...      ...  ...       ...    ...  ...    ...    ...    ...   \n",
       "1635             d        1  125     61.67  71.23  ...    0.0   0.00    0.0   \n",
       "1636             d        1   47     10.78  66.48  ...    0.0   0.00    0.0   \n",
       "1637             d        1   67     62.69  96.31  ...    0.0   0.00    0.0   \n",
       "1638             d        1   45     97.53  74.76  ...    0.0   0.00    0.0   \n",
       "1639             d        1   45     88.08  97.69  ...    0.0   0.00    0.0   \n",
       "\n",
       "      Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
       "0        0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
       "1        0.0  1.11    0.0     0.00     0.00    0.00    0.0  \n",
       "2        0.0  0.00    0.0     1.94     0.00    0.97    0.0  \n",
       "3        0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
       "4        0.0  0.00    0.0     1.10     0.00    0.00    0.0  \n",
       "...      ...   ...    ...      ...      ...     ...    ...  \n",
       "1635     0.8  0.00    0.0     4.80     0.00    0.00    0.0  \n",
       "1636     0.0  0.00    0.0     0.00     4.26    0.00    0.0  \n",
       "1637     0.0  0.00    0.0     5.97     0.00    0.00    0.0  \n",
       "1638     0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
       "1639     0.0  2.22    0.0     0.00     0.00    0.00    0.0  \n",
       "\n",
       "[1640 rows x 101 columns]>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv ('LIWC-15 Results - sign_events_data_statements - LIWC Analysis')\n",
    "# simple EDA\n",
    "# print(df)\n",
    "# print(df.columns)\n",
    "print(f'shape: {df.shape}')  # should be 1640 x 6\n",
    "df.head\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the LIWC markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1640, 101)\n",
      "Index(['signevent', 'q1', 'q2', 'unid', 'id', 'outcome_class', 'Segment', 'WC',\n",
      "       'Analytic', 'Clout',\n",
      "       ...\n",
      "       'Colon', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro',\n",
      "       'Parenth', 'OtherP', 'Emoji'],\n",
      "      dtype='object', length=101)\n",
      "['AllPunc']\n",
      "['Analytic', 'Apostro', 'Authentic', 'Clout', 'Colon', 'Comma', 'Dash', 'Dic', 'Emoji', 'Exclam']\n",
      "['OtherP', 'Parenth', 'Period', 'QMark', 'Quote', 'Segment', 'SemiC', 'Sixltr', 'Tone', 'WC']\n",
      "['WPS', 'achieve', 'adj', 'adverb', 'affect', 'affiliation', 'anger', 'anx', 'article', 'assent']\n",
      "['auxverb', 'bio', 'body', 'cause', 'certain', 'cogproc', 'compare', 'conj', 'death', 'differ']\n",
      "['discrep', 'drives', 'family', 'feel', 'female', 'filler', 'focusfuture', 'focuspast', 'focuspresent', 'friend']\n",
      "['function', 'health', 'hear', 'home', 'i', 'id', 'informal', 'ingest', 'insight', 'interrog']\n",
      "['ipron', 'leisure', 'male', 'money', 'motion', 'negate', 'negemo', 'netspeak', 'nonflu', 'number']\n",
      "['outcome_class', 'percept', 'posemo', 'power', 'ppron', 'prep', 'pronoun', 'q1', 'q2', 'quant']\n",
      "['relativ', 'relig', 'reward', 'risk', 'sad', 'see', 'sexual', 'shehe', 'signevent', 'social']\n",
      "['space', 'swear', 'tentat', 'they', 'time', 'unid', 'verb', 'we', 'work', 'you']\n",
      "      ingest   bio  Analytic  number  leisure  Apostro  focuspast  reward   \n",
      "0       0.00  0.88     27.78    1.77     1.77     0.00       4.42    3.54  \\\n",
      "1       0.00  0.00     52.71    4.44     1.11     0.00      10.00    0.00   \n",
      "2       1.94  3.88     51.60    0.00     1.94     1.94       4.85    3.88   \n",
      "3       0.00  0.00     74.02    1.49     5.97     0.00       0.00    2.99   \n",
      "4       4.40  4.40     84.75    1.10     5.49     1.10       2.20    2.20   \n",
      "...      ...   ...       ...     ...      ...      ...        ...     ...   \n",
      "1635    0.00  0.80     61.67    0.80     0.80     4.80       3.20    1.60   \n",
      "1636    0.00  0.00     10.78    2.13     2.13     0.00       0.00    0.00   \n",
      "1637    0.00  4.48     62.69    0.00     1.49     5.97       7.46    2.99   \n",
      "1638    0.00  0.00     97.53   11.11     6.67     0.00       8.89    0.00   \n",
      "1639    6.67  6.67     88.08    2.22    11.11     0.00       0.00    2.22   \n",
      "\n",
      "       WC  pronoun  \n",
      "0     113    15.04  \n",
      "1      90    18.89  \n",
      "2     103    11.65  \n",
      "3      67    11.94  \n",
      "4      91    14.29  \n",
      "...   ...      ...  \n",
      "1635  125    16.00  \n",
      "1636   47    21.28  \n",
      "1637   67    13.43  \n",
      "1638   45     4.44  \n",
      "1639   45     8.89  \n",
      "\n",
      "[1640 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "liwc_15 = pd.read_csv ('LIWC-15 Results - sign_events_data_statements - LIWC Analysis')\n",
    "# simple EDA\n",
    "\n",
    "print(f'shape: {liwc_15.shape}')  # should be 1640, \n",
    "print(liwc_15.columns)\n",
    "cols = sorted(liwc_15.columns)\n",
    "nb_attrib_per_line = 10\n",
    "print_buf = []\n",
    "for i, attrib in enumerate(cols):\n",
    "    print_buf.append(attrib)\n",
    "    if i % nb_attrib_per_line == 0:\n",
    "        print(print_buf)\n",
    "        print_buf = []\n",
    "\n",
    "truth_markers = df[['ingest', 'bio', 'Analytic', 'number', 'leisure', 'focusfuture']]\n",
    "deception_markers = df[['Apostro', 'focuspast', 'reward', 'WC', 'pronoun', 'ppron', 'Exclam', 'Tone']]\n",
    "liwc_markers = df[['ingest', 'bio', 'Analytic', 'number', 'leisure', 'Apostro', 'focuspast', 'reward', 'WC', 'pronoun']]\n",
    "# print(truth_markers)\n",
    "# print(deception_markers)\n",
    "print(liwc_markers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some quick test to see how the truth/deceit markers are bahaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ingest\": \"0       0.00\\n1       0.00\\n2       1.94\\n3       0.00\\n4       4.40\\n        ... \\n1635    0.00\\n1636    0.00\\n1637    0.00\\n1638    0.00\\n1639    6.67\\nName: ingest, Length: 1640, dtype: float64\", \"bio\": \"0       0.88\\n1       0.00\\n2       3.88\\n3       0.00\\n4       4.40\\n        ... \\n1635    0.80\\n1636    0.00\\n1637    4.48\\n1638    0.00\\n1639    6.67\\nName: bio, Length: 1640, dtype: float64\", \"Analytic\": \"0       27.78\\n1       52.71\\n2       51.60\\n3       74.02\\n4       84.75\\n        ...  \\n1635    61.67\\n1636    10.78\\n1637    62.69\\n1638    97.53\\n1639    88.08\\nName: Analytic, Length: 1640, dtype: float64\", \"number\": \"0        1.77\\n1        4.44\\n2        0.00\\n3        1.49\\n4        1.10\\n        ...  \\n1635     0.80\\n1636     2.13\\n1637     0.00\\n1638    11.11\\n1639     2.22\\nName: number, Length: 1640, dtype: float64\", \"leisure\": \"0        1.77\\n1        1.11\\n2        1.94\\n3        5.97\\n4        5.49\\n        ...  \\n1635     0.80\\n1636     2.13\\n1637     1.49\\n1638     6.67\\n1639    11.11\\nName: leisure, Length: 1640, dtype: float64\", \"Apostro\": \"0       0.00\\n1       0.00\\n2       1.94\\n3       0.00\\n4       1.10\\n        ... \\n1635    4.80\\n1636    0.00\\n1637    5.97\\n1638    0.00\\n1639    0.00\\nName: Apostro, Length: 1640, dtype: float64\", \"focuspast\": \"0        4.42\\n1       10.00\\n2        4.85\\n3        0.00\\n4        2.20\\n        ...  \\n1635     3.20\\n1636     0.00\\n1637     7.46\\n1638     8.89\\n1639     0.00\\nName: focuspast, Length: 1640, dtype: float64\", \"reward\": \"0       3.54\\n1       0.00\\n2       3.88\\n3       2.99\\n4       2.20\\n        ... \\n1635    1.60\\n1636    0.00\\n1637    2.99\\n1638    0.00\\n1639    2.22\\nName: reward, Length: 1640, dtype: float64\", \"WC\": \"0       113\\n1        90\\n2       103\\n3        67\\n4        91\\n       ... \\n1635    125\\n1636     47\\n1637     67\\n1638     45\\n1639     45\\nName: WC, Length: 1640, dtype: int64\", \"pronoun\": \"0       15.04\\n1       18.89\\n2       11.65\\n3       11.94\\n4       14.29\\n        ...  \\n1635    16.00\\n1636    21.28\\n1637    13.43\\n1638     4.44\\n1639     8.89\\nName: pronoun, Length: 1640, dtype: float64\"}\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import json\n",
    "# TODO see if this can be more friendlier if GPT does not know about LIWC\n",
    "def construct_liwc_attributes_json(row):\n",
    "    # print('class:', 'truthful' if df.iloc[row]['outcome_class'] == 't' else 'deceptive')\n",
    "    # print(liwc_markers.iloc[row])\n",
    "    # print(f'q1:\\n {textwrap.fill(df.iloc[row][\"q1\"], 100)}')\n",
    "    # print(f'q2:\\n {textwrap.fill(df.iloc[row][\"q2\"], 100)}')\n",
    "    \n",
    "    attributes = ['ingest', 'bio', 'Analytic', 'number', 'leisure', 'Apostro', 'focuspast', 'reward', 'WC', 'pronoun']\n",
    "    data = {}\n",
    "    for attribute in attributes:\n",
    "        data[attribute] = str(df[attribute])\n",
    "    \n",
    "    return json.dumps(data)\n",
    "\n",
    "# print(construct_liwc_attributes_json(df.iloc[269]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth df shape: (783, 101)\n",
      "                                             signevent   \n",
      "0                                  My brothers wedding  \\\n",
      "1                   Going to collect 2 new pet rabbits   \n",
      "2    Getting dinner with my friend Shan and my boyf...   \n",
      "3    mountain bike ride with my boyfriend and daughter   \n",
      "4    I will be going to the cat cafe in Glasgow on ...   \n",
      "..                                                 ...   \n",
      "778                          Go to NJ to visit cousins   \n",
      "779  I am going to visit my mum and gran who I've n...   \n",
      "780                                           Swimming   \n",
      "781                    Going for coffee with the girls   \n",
      "782                    Going to the cinema with Yasmin   \n",
      "\n",
      "                                                    q1   \n",
      "0    My little brother is getting married next Satu...  \\\n",
      "1    I will be driving for 80-90 minutes across Lon...   \n",
      "2    We were planning to get dinner somewhere near ...   \n",
      "3    We are going to cannock chase with the mountai...   \n",
      "4    I will be getting up Tuesday morning to go int...   \n",
      "..                                                 ...   \n",
      "778  I am going to take a train and then a bus to N...   \n",
      "779  I am going to get on a plane and fly to Buchar...   \n",
      "780  I bring my little girl swimming all the time s...   \n",
      "781  We all meet after we drop the kids ff at schoo...   \n",
      "782  I am meeting Yasmin at the train station tonig...   \n",
      "\n",
      "                                                    q2      unid   id   \n",
      "0    My brother and Kate have a daughter who will b...  FU304384    1  \\\n",
      "1    I saw the as for them a week ago but was going...  jr125663    2   \n",
      "2    I haven't seen Shan in a while and have been m...  xE150711    3   \n",
      "3    We will be taking our trek and wonder mountain...  RA263881    4   \n",
      "4    I have looked into the cat cafe to know that t...  RD298286    5   \n",
      "..                                                 ...       ...  ...   \n",
      "778  I am leaving on Saturday to their house. It wi...  OK943376  779   \n",
      "779  I will not be at work next week and I have a p...  sM811211  780   \n",
      "780  We do it weekly and i am currently looking a c...  OD017473  781   \n",
      "781  The girls are called Joanne and Julie although...  cg842481  782   \n",
      "782  The incredible 2 starts at savoy cinema at 8:3...  Lj421188  783   \n",
      "\n",
      "    outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "0        truthful        1  113     27.78  99.00  ...   0.00   0.00    0.0  \\\n",
      "1        truthful        1   90     52.71  71.09  ...   0.00   0.00    0.0   \n",
      "2        truthful        1  103     51.60  38.53  ...   0.00   0.97    0.0   \n",
      "3        truthful        1   67     74.02  93.21  ...   0.00   0.00    0.0   \n",
      "4        truthful        1   91     84.75  58.68  ...   0.00   0.00    0.0   \n",
      "..            ...      ...  ...       ...    ...  ...    ...    ...    ...   \n",
      "778      truthful        1   53     66.22  57.49  ...   0.00   0.00    0.0   \n",
      "779      truthful        1   44     80.14   8.65  ...   0.00   0.00    0.0   \n",
      "780      truthful        1   41     33.72  68.71  ...   0.00   0.00    0.0   \n",
      "781      truthful        1  225     45.13  73.31  ...   0.00   0.00    0.0   \n",
      "782      truthful        1   36     98.14  60.95  ...   5.56   0.00    0.0   \n",
      "\n",
      "     Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "0       0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "1       0.0  1.11    0.0     0.00      0.0    0.00    0.0  \n",
      "2       0.0  0.00    0.0     1.94      0.0    0.97    0.0  \n",
      "3       0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "4       0.0  0.00    0.0     1.10      0.0    0.00    0.0  \n",
      "..      ...   ...    ...      ...      ...     ...    ...  \n",
      "778     0.0  1.89    0.0     0.00      0.0    0.00    0.0  \n",
      "779     0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "780     0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "781     0.0  0.00    0.0     2.67      0.0    0.00    0.0  \n",
      "782     0.0  0.00    0.0     0.00      0.0    0.00    0.0  \n",
      "\n",
      "[783 rows x 101 columns]\n",
      "deceit df shape: (857, 101)\n",
      "                                              signevent   \n",
      "783   Going to the cat cafe in Glasgow on Tuesday fo...  \\\n",
      "784   We will be headed to Wales for a motorcycle ho...   \n",
      "785                           Training for a trail race   \n",
      "786   My husband and I will be heading to the Librar...   \n",
      "787   I am going to spend the whole day with my neic...   \n",
      "...                                                 ...   \n",
      "1635  Taking part in a 6 mile walk with a friend of ...   \n",
      "1636               Taking my Nephew to a Zoology museum   \n",
      "1637  Me and my best friend Cara are going to the zo...   \n",
      "1638                          The RAF 100 Bicycle Trail   \n",
      "1639         Going to a drum and bass rave with friends   \n",
      "\n",
      "                                                     q1   \n",
      "783   I'm going to the cat cafe where I met my girlf...  \\\n",
      "784   On Monday we are taking the train to Cardiff. ...   \n",
      "785   Ok so this is my first ever running race to he...   \n",
      "786   My husband and I are heading to Mauritius the ...   \n",
      "787   I am going to be spending a whole day with my ...   \n",
      "...                                                 ...   \n",
      "1635  I'm going on a walk with a friend of mine and ...   \n",
      "1636  I am going to a museum in Manchester that focu...   \n",
      "1637  We used to be housemates and always watched th...   \n",
      "1638  The RAF 100 Bicycle Trail is a commemorative t...   \n",
      "1639  Going to meet up with friends. Have lunch and ...   \n",
      "\n",
      "                                                     q2      unid    id   \n",
      "783   Well, it was the place where I met my girlfrie...  Ko917447   784  \\\n",
      "784   I'm not sure really as its not something booke...  RL904488   785   \n",
      "785   So I have been training for months for this I ...  ry285586   786   \n",
      "786   We'll be going to our local library in Chorlto...  GE115682   787   \n",
      "787   My sister really does live in scotland and I d...  if897876   788   \n",
      "...                                                 ...       ...   ...   \n",
      "1635  I love walking, and go a lot with my partner a...  jS030001  1636   \n",
      "1636  His name is Jack and he is 10. My brother (his...  Vp529563  1637   \n",
      "1637  Cara and I have been friends since high school...  Bn541159  1638   \n",
      "1638  The Trail used to be called the RAF 100 Voices...  WL145697  1639   \n",
      "1639  We have booked train tickets. Ordered rave tic...  AE402554  1640   \n",
      "\n",
      "     outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "783      deceptive        1   86     50.06  85.24  ...    0.0    0.0    0.0  \\\n",
      "784      deceptive        1  109     64.90  82.06  ...    0.0    0.0    0.0   \n",
      "785      deceptive        1  190     23.53  15.86  ...    0.0    0.0    0.0   \n",
      "786      deceptive        1   83     73.76  97.97  ...    0.0    0.0    0.0   \n",
      "787      deceptive        1  121     53.19  28.15  ...    0.0    0.0    0.0   \n",
      "...            ...      ...  ...       ...    ...  ...    ...    ...    ...   \n",
      "1635     deceptive        1  125     61.67  71.23  ...    0.0    0.0    0.0   \n",
      "1636     deceptive        1   47     10.78  66.48  ...    0.0    0.0    0.0   \n",
      "1637     deceptive        1   67     62.69  96.31  ...    0.0    0.0    0.0   \n",
      "1638     deceptive        1   45     97.53  74.76  ...    0.0    0.0    0.0   \n",
      "1639     deceptive        1   45     88.08  97.69  ...    0.0    0.0    0.0   \n",
      "\n",
      "      Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "783     0.00  0.00    0.0     3.49     0.00     0.0    0.0  \n",
      "784     0.00  0.00    0.0     3.67     1.83     0.0    0.0  \n",
      "785     0.00  0.00    0.0     2.63     0.00     0.0    0.0  \n",
      "786     1.20  0.00    0.0     1.20     0.00     0.0    0.0  \n",
      "787     0.83  0.00    0.0     4.13     0.00     0.0    0.0  \n",
      "...      ...   ...    ...      ...      ...     ...    ...  \n",
      "1635    0.80  0.00    0.0     4.80     0.00     0.0    0.0  \n",
      "1636    0.00  0.00    0.0     0.00     4.26     0.0    0.0  \n",
      "1637    0.00  0.00    0.0     5.97     0.00     0.0    0.0  \n",
      "1638    0.00  0.00    0.0     0.00     0.00     0.0    0.0  \n",
      "1639    0.00  2.22    0.0     0.00     0.00     0.0    0.0  \n",
      "\n",
      "[857 rows x 101 columns]\n",
      "non-repeating random numbers are:\n",
      "random truth list:\n",
      ",                                              signevent   \n",
      "661  i am going camping in scotland with my gf on t...  \\\n",
      "39   I plan on meeting friend in town for a night o...   \n",
      "215    Complete healing session with my Friend Divine.   \n",
      "\n",
      "                                                    q1   \n",
      "661  i am driving up to a place called peebles in s...  \\\n",
      "39   I will take the bus from my town and go to tow...   \n",
      "215  Every week or so me and my friend Divine parti...   \n",
      "\n",
      "                                                    q2      unid   id   \n",
      "661  The campsite we are going to is called crossbu...  VR950867  662  \\\n",
      "39   I have already planned on borrowing money unti...  yY050275   40   \n",
      "215  My friend and I have been doing these sessions...  uD416433  216   \n",
      "\n",
      "    outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "661      truthful        1   84     90.75  95.20  ...    0.0    0.0    0.0  \\\n",
      "39       truthful        1   56     76.76  50.00  ...    0.0    0.0    0.0   \n",
      "215      truthful        1  114     26.30  53.51  ...    0.0    0.0    0.0   \n",
      "\n",
      "     Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "661     0.0   0.0    0.0     0.00      0.0     0.0    0.0  \n",
      "39      0.0   0.0    0.0     0.00      0.0     0.0    0.0  \n",
      "215     0.0   0.0    0.0     0.88      0.0     0.0    0.0  \n",
      "\n",
      "[3 rows x 101 columns]\n",
      "truth indices:\" [661, 39, 215]\n",
      "non-repeating random numbers are:\n",
      "random deceit list:\n",
      ",                                               signevent   \n",
      "1063  I'm going to be running in a 5k.  I'm very exc...  \\\n",
      "1153  I will be spending an afternoon with my friend...   \n",
      "1413                                            angling   \n",
      "\n",
      "                                                     q1   \n",
      "1063  As a part of the local holiday coming up, I'm ...  \\\n",
      "1153  We are planning on taking our kites to an area...   \n",
      "1413  go out in boat and using live bait fish using ...   \n",
      "\n",
      "                                                     q2      unid    id   \n",
      "1063  I've paid the $50 entrance fee already and hav...  PT229681  1064  \\\n",
      "1153  Our kite flying trip was planned for about two...  kt543396  1154   \n",
      "1413     we have to wait for high tide to go out to sea  xe033698  1414   \n",
      "\n",
      "     outcome_class  Segment   WC  Analytic  Clout  ...  Colon  SemiC  QMark   \n",
      "1063     deceptive        1  127     90.77  31.84  ...   0.79    0.0    0.0  \\\n",
      "1153     deceptive        1  160     33.60  94.78  ...   0.00    0.0    0.0   \n",
      "1413     deceptive        1   32     99.00  73.40  ...   0.00    0.0    0.0   \n",
      "\n",
      "      Exclam  Dash  Quote  Apostro  Parenth  OtherP  Emoji  \n",
      "1063     0.0  0.79    0.0     1.57     1.57    0.79    0.0  \n",
      "1153     0.0  0.00    0.0     0.63     0.00    0.00    0.0  \n",
      "1413     0.0  0.00    0.0     0.00     0.00    0.00    0.0  \n",
      "\n",
      "[3 rows x 101 columns]\n",
      "deceit indices: [1063, 1153, 1413]\n",
      "truth + deceit indices\" [661, 39, 215, 1063, 1153, 1413]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3423/4237064160.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  truth_df['outcome_class'] = df['outcome_class'].replace('t','truthful')\n",
      "/tmp/ipykernel_3423/4237064160.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deceit_df['outcome_class'] = df['outcome_class'].replace('d','deceptive')\n"
     ]
    }
   ],
   "source": [
    "def filter_by_class(df, category):\n",
    "   return df[df['outcome_class']== category]\n",
    "\n",
    "truth_df = filter_by_class(df, 't')\n",
    "# print(truth_df)\n",
    "print(f'truth df shape: {truth_df.shape}')  # should be 1640 x 6\n",
    "\n",
    "# replace with a more expressive word, truthful\n",
    "truth_df['outcome_class'] = df['outcome_class'].replace('t','truthful')\n",
    "print(truth_df)\n",
    "\n",
    "deceit_df = filter_by_class(df, 'd')\n",
    "# print(deceit_df)\n",
    "print(f'deceit df shape: {deceit_df.shape}')  # should be 1640 x 6\n",
    "\n",
    "# replace with a more expressive word, deceitful\n",
    "deceit_df['outcome_class'] = df['outcome_class'].replace('d','deceptive')\n",
    "print(deceit_df)\n",
    "\n",
    "# pick random non-repeating rows\n",
    "def pick_randon_non_repeating(df, quantity):\n",
    "    import random\n",
    "    rand_df = pd.DataFrame()\n",
    "    random_list = random.sample(range(df.shape[0]), quantity)\n",
    "    print(\"non-repeating random numbers are:\")\n",
    "    return df.iloc[random_list], random_list\n",
    "\n",
    "random_truth_df, truth_indices_list = pick_randon_non_repeating(truth_df, nb_few_shot_samples_of_each_class)\n",
    "print(f'random truth list:\\n, {random_truth_df}')\n",
    "print(f'truth indices:\" {truth_indices_list}')\n",
    "\n",
    "random_deceit_df, deceit_indices_list = pick_randon_non_repeating(deceit_df, nb_few_shot_samples_of_each_class)\n",
    "print(f'random deceit list:\\n, {random_deceit_df}')\n",
    "deceit_indices_list = [x + truth_df.shape[0] for x in deceit_indices_list] # do this to exclude from poriginal list\n",
    "print(f'deceit indices: {deceit_indices_list}')\n",
    "\n",
    "random_truth_deceit_df = pd.concat([random_truth_df, random_deceit_df])\n",
    "few_shot_list = truth_indices_list + deceit_indices_list\n",
    "print(f'truth + deceit indices\" {few_shot_list}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the OpenAI call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_chat_completion_with_backoff(prompt, model=\"gpt-3.5-turbe\"):\n",
    "    return get_chat_completion(prompt, model)\n",
    "\n",
    "def get_completion(prompt, model='text-davinci-003'):\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        model=model\n",
    "    )\n",
    "    return response.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = f\"\"\"\n",
    "You are tasked to classify the response to questions into two classes: truthful or deceptive.\n",
    "You'll be presented with the following pieces of information on an activity:\n",
    "(1) The title of the activity.\n",
    "(2) An answwer to a question: Please describe your activity. Be as specific as possible.\n",
    "(3) A answer to a follow-on question: What information can you give us to reassure us that you are telling the truth?\n",
    "(4) A Linguistic Inquiry Word Count (LIWC) category values as JSON data\n",
    "Complete the response with either 'truthful' or 'deceptive'.\n",
    "\n",
    "Here are a few examples delimited by triple backticks:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_1_heading = \"\"\"Response #1:\\n\"\"\"\n",
    "response_2_heading = \"\"\"Response #2:\\n\"\"\"\n",
    "\n",
    "liwc_header = \"\"\"Libguistic Inquiry Word Count (LIWC):\\n\"\"\"\n",
    "\n",
    "def construct_activity_scenario(row):\n",
    "    # activity_header = 'Title of the Activity: ' + new_line\n",
    "    activity_header = 'Activity: ' + new_line\n",
    "    activity_description_header = 'Question #1: \\nPlease describe your activity. Be as specific as possible.'\n",
    "\n",
    "    activity_reassurance_header = 'Question #2: \\nWhat information can you give us to reassure us that you are telling the truth?'\n",
    "\n",
    "    activity = activity_header + row['signevent'] + new_line\n",
    "    q1 = activity_description_header + new_line + response_1_heading + row['q1'] + new_line\n",
    "    q2 = activity_reassurance_header + new_line + response_2_heading + row['q2'] + new_line\n",
    "    return activity + q1 + q2\n",
    "\n",
    "def construct_outcome(row):\n",
    "    outcome = \"Is the response truthful or deceptive?\\n\"\n",
    "    return outcome  + row['outcome_class'] + new_line\n",
    "\n",
    "def construct_liwc_json(row):\n",
    "    pass\n",
    "\n",
    "def construct_few_shot_prompt(few_shot_df, infer_row):\n",
    "    # constructed as a list\n",
    "    prompt = []\n",
    "    prompt.append(intro)\n",
    "    \n",
    "    for _, row in few_shot_df.iterrows():\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(construct_activity_scenario(row))\n",
    "        prompt.append(construct_outcome(row))\n",
    "        prompt.append(delimiter)\n",
    "        prompt.append(new_line)    \n",
    "        prompt.append(liwc_header)\n",
    "        prompt.append(construct_liwc_attributes_json(row))\n",
    "        prompt.append(new_line)\n",
    "\n",
    "    prompt.append(delimiter)\n",
    "    prompt.append(construct_activity_scenario(infer_row))\n",
    "    prompt.append(construct_outcome(infer_row)) # has to have a blank outcome to be filled by the llm\n",
    "    prompt.append(delimiter)\n",
    "\n",
    "\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_indices(df, total, exclude_list):\n",
    "    import random\n",
    "    rand_list = []\n",
    "    count = 0\n",
    "    while count < total:\n",
    "        rand_row = random.randrange(df.shape[0])\n",
    "        if rand_row not in exclude_list:\n",
    "            rand_list.append(rand_row)\n",
    "            count += 1\n",
    "    return rand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test indices: [1086, 596, 954, 194, 182, 1492, 1129, 547, 1440, 862]\n"
     ]
    }
   ],
   "source": [
    "test_indices = create_test_indices(df, nb_test_samples, few_shot_list)  # exclude the ones in the few shot list\n",
    "# test_indices = [1435]\n",
    "print(f'test indices: {test_indices}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---row:signevent    i am going camping in scotland with my gf on t...\n",
      "q1           i am driving up to a place called peebles in s...\n",
      "q2           The campsite we are going to is called crossbu...\n",
      "unid                                                  VR950867\n",
      "id                                                         662\n",
      "                                   ...                        \n",
      "Quote                                                      0.0\n",
      "Apostro                                                    0.0\n",
      "Parenth                                                    0.0\n",
      "OtherP                                                     0.0\n",
      "Emoji                                                      0.0\n",
      "Name: 661, Length: 101, dtype: object +++++++++++attribute: ingest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3423/3395453933.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  infer_row['outcome_class'] = ''\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'i am going camping in scotland with my gf on tue for a few days'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m infer_row[\u001b[39m'\u001b[39m\u001b[39moutcome_class\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(f'Original\\n:{df.loc[index]}')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# print(f'infer row\\n: {infer_row}')\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m prompt \u001b[39m=\u001b[39m construct_few_shot_prompt(random_truth_deceit_df, infer_row)\n\u001b[1;32m     15\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(prompt)\n\u001b[1;32m     17\u001b[0m \u001b[39m# print(f'Prompt:\\n{prompt}')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[53], line 50\u001b[0m, in \u001b[0;36mconstruct_few_shot_prompt\u001b[0;34m(few_shot_df, infer_row)\u001b[0m\n\u001b[1;32m     48\u001b[0m     prompt\u001b[39m.\u001b[39mappend(new_line)    \n\u001b[1;32m     49\u001b[0m     prompt\u001b[39m.\u001b[39mappend(liwc_header)\n\u001b[0;32m---> 50\u001b[0m     prompt\u001b[39m.\u001b[39mappend(construct_liwc_attributes_json(row))\n\u001b[1;32m     51\u001b[0m     prompt\u001b[39m.\u001b[39mappend(new_line)\n\u001b[1;32m     53\u001b[0m prompt\u001b[39m.\u001b[39mappend(delimiter)\n",
      "Cell \u001b[0;32mIn[60], line 14\u001b[0m, in \u001b[0;36mconstruct_liwc_attributes_json\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m attribute \u001b[39min\u001b[39;00m attributes:\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m---row:\u001b[39m\u001b[39m{\u001b[39;00mrow\u001b[39m}\u001b[39;00m\u001b[39m +++++++++++attribute: \u001b[39m\u001b[39m{\u001b[39;00mattribute\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     data[attribute] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(df\u001b[39m.\u001b[39;49miloc[row][attribute])\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mdumps(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/babyagi/lib/python3.9/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/babyagi/lib/python3.9/site-packages/pandas/core/indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m \u001b[39m# a list of integers\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1647\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_list_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1649\u001b[0m \u001b[39m# a single integer\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1651\u001b[0m     key \u001b[39m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/babyagi/lib/python3.9/site-packages/pandas/core/indexing.py:1618\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[39mReturn Series values by list or array of integers.\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[39m`axis` can only be zero.\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1618\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_take_with_is_copy(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1619\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1620\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpositional indexers are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/babyagi/lib/python3.9/site-packages/pandas/core/generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3940\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   3941\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3943\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3946\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3947\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3948\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3950\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/envs/babyagi/lib/python3.9/site-packages/pandas/core/generic.py:3923\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3917\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3918\u001b[0m \u001b[39mInternal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[1;32m   3919\u001b[0m \n\u001b[1;32m   3920\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3921\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3922\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(indices, \u001b[39mslice\u001b[39m):\n\u001b[0;32m-> 3923\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(indices, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mintp)\n\u001b[1;32m   3924\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3925\u001b[0m         axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3926\u001b[0m         \u001b[39mand\u001b[39;00m indices\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3927\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   3928\u001b[0m         \u001b[39mand\u001b[39;00m is_range_indexer(indices, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[1;32m   3929\u001b[0m     ):\n\u001b[1;32m   3930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/babyagi/lib/python3.9/site-packages/pandas/core/series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[39mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    916\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m--> 917\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    919\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'i am going camping in scotland with my gf on tue for a few days'"
     ]
    }
   ],
   "source": [
    "y_ground_truth = []  # for computing F1-score\n",
    "y_predicted = []\n",
    "\n",
    "for index in test_indices:\n",
    "    infer_row = df.loc[index]  \n",
    "    # print(f'Inferring the `class_outcome` for:\\n{infer_row}')\n",
    "    ground_truth = 'truthful' if infer_row['outcome_class'] == 't' else 'deceptive'\n",
    "    # mask the `outcome_class` field since you want to predict it\n",
    "    infer_row['outcome_class'] = ''\n",
    "\n",
    "    # print(f'Original\\n:{df.loc[index]}')\n",
    "    # print(f'infer row\\n: {infer_row}')\n",
    "\n",
    "    prompt = construct_few_shot_prompt(random_truth_deceit_df, infer_row)\n",
    "    prompt = ''.join(prompt)\n",
    "    \n",
    "    # print(f'Prompt:\\n{prompt}')\n",
    "\n",
    "    response = get_chat_completion_with_backoff(\n",
    "        prompt=prompt,\n",
    "        model=MODEL,\n",
    "    )    \n",
    "        \n",
    "    print(f'INDEX: {index} GROUND TRUTH: {ground_truth}, RESPONSE: {response} - {\"wrong\" if ground_truth != response else \"correct\"}')\n",
    "    y_ground_truth.append(ground_truth)\n",
    "    y_predicted.append(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('Weighted F1-score:', f1_score(y_ground_truth, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyagi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
